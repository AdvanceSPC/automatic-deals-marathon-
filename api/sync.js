// api/sync.js
import {
  fetchCSVFromS3,
  readProcessedList,
  saveProcessedList,
  testS3Connections,
  getFileProgress,
  saveFileProgress,
  markChunkAsCompleted
} from "../utils/s3Helpers.js";
import { sendToHubspot } from "../utils/hubspot.js";
import { ListObjectsV2Command, S3Client } from "@aws-sdk/client-s3";

const AWS1_BUCKET = process.env.AWS1_BUCKET;
const s3Read = new S3Client({
  region: process.env.AWS1_REGION,
  credentials: {
    accessKeyId: process.env.AWS1_ACCESS_KEY_ID,
    secretAccessKey: process.env.AWS1_SECRET_ACCESS_KEY,
  },
});

export const config = {
  runtime: "nodejs",
  maxDuration: 300, 
};

export default async function handler(req, res) {
  const executionStart = Date.now();
  const MAX_EXECUTION_TIME = 290000;
  
  console.log("üîå Verificando conexi√≥n con buckets S3...");

  const s3Ok = await testS3Connections();
  if (!s3Ok) {
    return res.status(500).send("‚ùå Fallo en conexi√≥n a uno o ambos buckets S3.");
  }

  console.log("üìÉ Cargando historial...");
  const processed = await readProcessedList();

  const command = new ListObjectsV2Command({
    Bucket: AWS1_BUCKET,
    Prefix: "delta_negocio_",
  });

  const { Contents = [] } = await s3Read.send(command);
  const nuevosArchivos = Contents.map((obj) => obj.Key)
    .filter((key) => key.endsWith(".csv"))
    .filter((key) => !processed.includes(key))
    .sort(); 

  if (nuevosArchivos.length === 0) {
    console.log("üü° No hay nuevos archivos para procesar.");
    return res.status(200).send("üü° No hay archivos nuevos.");
  }

  console.log(`üìÅ Encontrados ${nuevosArchivos.length} archivos nuevos para procesar`);

  // Procesar solo 1 archivo para evitar timeouts
  const fileName = nuevosArchivos[0];
  
  try {
    const elapsed = Date.now() - executionStart;
    if (elapsed > MAX_EXECUTION_TIME * 0.05) { 
      console.log("‚è∞ Tiempo insuficiente para procesar archivo");
      return res.status(200).send("‚è∞ Tiempo insuficiente - reintentar");
    }

    console.log(`‚¨áÔ∏è Procesando archivo: ${fileName}`);
    
    // Verificar si el archivo ya tiene progreso parcial
    const fileProgress = await getFileProgress(fileName);
    let deals;
    
    if (fileProgress && fileProgress.totalRecords) {
      console.log(`üîÑ Continuando procesamiento de ${fileName} desde chunk ${fileProgress.lastCompletedChunk + 1}`);
      console.log(`üìä Progreso anterior: ${fileProgress.processedRecords}/${fileProgress.totalRecords} registros`);
    } else {
      console.log(`üÜï Iniciando nuevo procesamiento de ${fileName}`);
    }
    
    deals = await fetchCSVFromS3(fileName);

    if (!deals.length) {
      console.warn(`‚ö†Ô∏è Archivo vac√≠o: ${fileName}`);
      processed.push(fileName);
      await saveProcessedList(processed);
      return res.status(200).send(`‚ö†Ô∏è Archivo vac√≠o procesado: ${fileName}`);
    }

    console.log(`üì® Enviando ${deals.length} negocios a HubSpot...`);
    
    // Verificar si el archivo es muy grande y necesita procesamiento parcial
    if (deals.length > 5000) {
      console.log(`üìè Archivo grande detectado (${deals.length} registros) - procesando en chunks`);
      
      const chunkSize = 2500;
      const totalChunks = Math.ceil(deals.length / chunkSize);
      let processedChunks = fileProgress ? fileProgress.lastCompletedChunk : 0;
      let totalProcessed = fileProgress ? fileProgress.processedRecords : 0;
      
      // Guardar el total de registros si es la primera vez
      if (!fileProgress || !fileProgress.totalRecords) {
        await saveFileProgress(fileName, {
          totalRecords: deals.length,
          totalChunks: totalChunks,
          processedRecords: 0,
          lastCompletedChunk: 0,
          status: 'processing'
        });
      }
      
      // Comenzar desde el siguiente chunk no completado
      const startChunk = processedChunks;
      
      for (let i = startChunk * chunkSize; i < deals.length; i += chunkSize) {
        const chunk = deals.slice(i, i + chunkSize);
        const chunkNumber = Math.floor(i/chunkSize) + 1;
        
        console.log(`üîÑ Procesando chunk ${chunkNumber} de ${totalChunks}`);
        
        // Calcular tiempo restante para este chunk
        const elapsedTime = Date.now() - executionStart;
        const remainingTime = MAX_EXECUTION_TIME - elapsedTime;
        
        // Necesitamos al menos 30 segundos para procesar un chunk
        if (remainingTime < 30000) {
          console.log(`‚è∞ Tiempo insuficiente para chunk ${chunkNumber} (${Math.round(remainingTime/1000)}s restantes)`);
          console.log(`üìä Progreso actual: ${processedChunks}/${totalChunks} chunks (${totalProcessed}/${deals.length} registros)`);
          
          // Guardar progreso antes de salir
          await saveFileProgress(fileName, {
            totalRecords: deals.length,
            totalChunks: totalChunks,
            processedRecords: totalProcessed,
            lastCompletedChunk: processedChunks,
            status: 'processing'
          });
          
          return res.status(200).send(`‚è∞ Procesamiento parcial: ${processedChunks}/${totalChunks} chunks completados`);
        }
        
        const result = await sendToHubspot(chunk, `${fileName}_chunk_${chunkNumber}`, remainingTime);
        
        // Marcar chunk como completado
        await markChunkAsCompleted(fileName, chunkNumber, chunk.length);
        processedChunks++;
        totalProcessed += chunk.length;
        
        console.log(`‚úÖ Chunk ${chunkNumber} completado. Progreso: ${processedChunks}/${totalChunks}`);
        
        // Actualizar progreso
        await saveFileProgress(fileName, {
          totalRecords: deals.length,
          totalChunks: totalChunks,
          processedRecords: totalProcessed,
          lastCompletedChunk: processedChunks,
          status: processedChunks === totalChunks ? 'completed' : 'processing'
        });
        
        // Verificar tiempo despu√©s de cada chunk
        const newElapsedTime = Date.now() - executionStart;
        if (newElapsedTime > MAX_EXECUTION_TIME * 0.85) {
          console.log(`‚è∞ L√≠mite de tiempo alcanzado despu√©s del chunk ${chunkNumber}`);
          console.log(`üìä Procesados ${processedChunks}/${totalChunks} chunks (${totalProcessed}/${deals.length} registros)`);
          return res.status(200).send(`‚è∞ Procesamiento parcial: ${processedChunks}/${totalChunks} chunks completados`);
        }
      }
      
      // Solo marcar como completamente procesado si se procesaron todos los chunks
      if (processedChunks === totalChunks) {
        processed.push(fileName);
        await saveFileProgress(fileName, {
          totalRecords: deals.length,
          totalChunks: totalChunks,
          processedRecords: totalProcessed,
          lastCompletedChunk: processedChunks,
          status: 'completed'
        });
        console.log(`‚úÖ Procesado exitosamente: ${fileName} (todos los chunks completados)`);
      } else {
        console.log(`‚ö†Ô∏è Procesamiento parcial: ${fileName} (${processedChunks}/${totalChunks} chunks)`);
        return res.status(200).send(`‚ö†Ô∏è Procesamiento parcial: ${processedChunks}/${totalChunks} chunks completados`);
      }
      
    } else {
      const remainingTime = MAX_EXECUTION_TIME - (Date.now() - executionStart);
      await sendToHubspot(deals, fileName, remainingTime);
      processed.push(fileName);
      console.log(`‚úÖ Procesado exitosamente: ${fileName}`);
    }
    
  } catch (error) {
    console.error(`‚ùå Error procesando ${fileName}:`, error);
    return res.status(500).send(`‚ùå Error procesando ${fileName}: ${error.message}`);
  }

  console.log("üíæ Actualizando historial...");
  await saveProcessedList(processed);

  const executionTime = ((Date.now() - executionStart) / 1000).toFixed(2);
  const response = `‚úÖ Procesado archivo: ${fileName} en ${executionTime}s. ${nuevosArchivos.length - 1} archivos pendientes.`;
  
  console.log(response);
  return res.status(200).send(response);
}
